{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fde0277f",
   "metadata": {},
   "source": [
    "## Create an endpoint from the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5c3e114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket sagemaker-ap-northeast-2-806174985048\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "import tarfile\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "sm_boto3 = boto3.client('sagemaker')\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "bucket = sess.default_bucket()  # this could also be a hard-coded bucket name\n",
    "\n",
    "print('Using bucket ' + bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7efb051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65c19d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "wget -q https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
    "mv adult.data ./data/adult.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee790fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv with column names\n",
    "column_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "df = pd.read_csv('data/adult.csv', names = column_names)\n",
    "\n",
    "df.replace('?',np.NaN,inplace=True)\n",
    "\n",
    "df_train_val, df_test, = train_test_split(df, test_size=0.1, random_state=42)\n",
    "df_train_val_no_target = df_train_val.drop('income', axis=1)\n",
    "\n",
    "df_test.to_csv('data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a94dd3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_ind = [i for i, x in enumerate(df_train_val_no_target.dtypes) if x != object]\n",
    "cat_ind = [i for i, x in enumerate(df_train_val_no_target.dtypes) if x == object]\n",
    "\n",
    "numeric_transformer = SimpleImputer(strategy='mean')\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_ind),\n",
    "    ('cat', categorical_transformer, cat_ind)\n",
    "])\n",
    "\n",
    "X = preprocessor.fit_transform(df_train_val_no_target)\n",
    "\n",
    "y = LabelEncoder().fit_transform(df_train_val.income)\n",
    "X = np.insert(X, 0, y, axis=1)\n",
    "\n",
    "# Save the ColumnTransformer to be used during inference\n",
    "with open('src/preprocess.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea97c587",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "np.savetxt(\"data/train.csv\", X_train, delimiter=\",\", fmt='%f')\n",
    "np.savetxt(\"data/val.csv\", X_val, delimiter=\",\", fmt='%f')\n",
    "\n",
    "prefix = 'sagemaker/blog'\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv'))\\\n",
    ".upload_file('data/train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv'))\\\n",
    ".upload_file('data/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cf674a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-16 23:05:21 Starting - Starting the training job...\n",
      "2022-10-16 23:05:45 Starting - Preparing the instances for trainingProfilerReport-1665961521: InProgress\n",
      ".........\n",
      "2022-10-16 23:07:10 Downloading - Downloading input data......\n",
      "2022-10-16 23:08:06 Training - Downloading the training image......\n",
      "2022-10-16 23:09:06 Training - Training image download completed. Training in progress.\u001b[34m[2022-10-16 23:09:10.557 ip-10-0-174-162.ap-northeast-2.compute.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34m[2022-10-16 23:09:10.902 ip-10-0-174-162.ap-northeast-2.compute.internal:1 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-10-16 23:09:10.903 ip-10-0-174-162.ap-northeast-2.compute.internal:1 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-10-16 23:09:10.903 ip-10-0-174-162.ap-northeast-2.compute.internal:1 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-10-16 23:09:10.904 ip-10-0-174-162.ap-northeast-2.compute.internal:1 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-10-16 23:09:10.904 ip-10-0-174-162.ap-northeast-2.compute.internal:1 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mINFO:root:Debug hook created from config\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 23443 rows and 108 columns\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 5861 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.14755#011validation-error:0.14417\u001b[0m\n",
      "\u001b[34m[2022-10-16 23:09:11.110 ip-10-0-174-162.ap-northeast-2.compute.internal:1 INFO hook.py:413] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2022-10-16 23:09:11.112 ip-10-0-174-162.ap-northeast-2.compute.internal:1 INFO hook.py:476] Hook is writing from the hook with pid: 1\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.14802#011validation-error:0.14366\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.14947#011validation-error:0.14503\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.14674#011validation-error:0.14400\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.14354#011validation-error:0.14315\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.14307#011validation-error:0.14383\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.14281#011validation-error:0.14059\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.14183#011validation-error:0.14178\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.14055#011validation-error:0.14093\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.14068#011validation-error:0.14025\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.13983#011validation-error:0.13991\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.13966#011validation-error:0.13940\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.13872#011validation-error:0.14247\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.13906#011validation-error:0.13974\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.13795#011validation-error:0.14127\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.13765#011validation-error:0.14008\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.13723#011validation-error:0.14042\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.13710#011validation-error:0.13974\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.13710#011validation-error:0.13991\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.13659#011validation-error:0.13991\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.13531#011validation-error:0.14008\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.13514#011validation-error:0.13906\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.13326#011validation-error:0.13803\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.13309#011validation-error:0.13820\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.13181#011validation-error:0.13735\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.13138#011validation-error:0.13786\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.13108#011validation-error:0.13684\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.13062#011validation-error:0.13667\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.13049#011validation-error:0.13598\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.13006#011validation-error:0.13615\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.12882#011validation-error:0.13598\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.12784#011validation-error:0.13479\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.12776#011validation-error:0.13479\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.12724#011validation-error:0.13479\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.12652#011validation-error:0.13513\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.12618#011validation-error:0.13496\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.12614#011validation-error:0.13564\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.12567#011validation-error:0.13479\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.12584#011validation-error:0.13462\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.12558#011validation-error:0.13462\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.12528#011validation-error:0.13462\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.12464#011validation-error:0.13428\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.12447#011validation-error:0.13428\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.12341#011validation-error:0.13411\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.12400#011validation-error:0.13377\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.12362#011validation-error:0.13325\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.12315#011validation-error:0.13308\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.12336#011validation-error:0.13291\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.12285#011validation-error:0.13445\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.12272#011validation-error:0.13377\u001b[0m\n",
      "\n",
      "2022-10-16 23:09:52 Uploading - Uploading generated training model\n",
      "2022-10-16 23:10:06 Completed - Training job completed\n",
      "ProfilerReport-1665961521: NoIssuesFound\n",
      "Training seconds: 174\n",
      "Billable seconds: 174\n"
     ]
    }
   ],
   "source": [
    "container = sagemaker.image_uris.retrieve('xgboost', boto3.Session().region_name, '1.2-1')\n",
    "\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":\"50\"}\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    get_execution_role(), \n",
    "                                    hyperparameters=hyperparameters,                                    \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "\n",
    "s3_input_train = TrainingInput(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = TrainingInput(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0936809c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘model’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91feafad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-ap-northeast-2-806174985048/sagemaker/blog/output/sagemaker-xgboost-2022-10-16-23-05-21-303/output/model.tar.gz to model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Save the model to be used during inference\n",
    "!aws s3 cp {xgb.model_data} model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e2bf69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
