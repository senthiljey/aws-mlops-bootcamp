{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af98daec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoleArn: arn:aws:iam::806174985048:role/service-role/AmazonSageMaker-ExecutionRole-20201218T151409\n",
      "Demo Bucket: sagemaker-ap-northeast-2-806174985048\n",
      "Capture path: s3://sagemaker-ap-northeast-2-806174985048/sagemaker/DEMO-ModelMonitor/datacapture\n",
      "Report path: s3://sagemaker-ap-northeast-2-806174985048/sagemaker/DEMO-ModelMonitor/reports\n"
     ]
    }
   ],
   "source": [
    "# Handful of configuration\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "from sagemaker import get_execution_role, session\n",
    "\n",
    "region= boto3.Session().region_name\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "role = get_execution_role()\n",
    "print(\"RoleArn: {}\".format(role))\n",
    "\n",
    "# You can use a different bucket, but make sure the role you chose for this notebook\n",
    "# has the s3:PutObject permissions. This is the bucket into which the data is captured\n",
    "bucket =  session.Session(boto3.Session()).default_bucket()\n",
    "print(\"Demo Bucket: {}\".format(bucket))\n",
    "prefix = 'sagemaker/DEMO-ModelMonitor'\n",
    "\n",
    "s3_capture_upload_path = f's3://{bucket}/{prefix}/datacapture'\n",
    "s3_report_path = f's3://{bucket}/{prefix}/reports'\n",
    "\n",
    "print(f\"Capture path: {s3_capture_upload_path}\")\n",
    "print(f\"Report path: {s3_report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "898c583b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! You are all set to proceed.\n"
     ]
    }
   ],
   "source": [
    "model_file = open(\"model/model.tar.gz\", 'rb')\n",
    "train_file = open(\"data/train.csv\", 'rb')\n",
    "test_file = open(\"data/test.csv\", 'rb')\n",
    "\n",
    "s3_model_key = os.path.join(prefix, 'model.tar.gz')\n",
    "s3_train_key = os.path.join(prefix, 'train.csv')\n",
    "s3_test_key = os.path.join(prefix, 'test.csv')\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(s3_model_key).upload_fileobj(model_file)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(s3_train_key).upload_fileobj(train_file)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(s3_test_key).upload_fileobj(test_file)\n",
    "\n",
    "print(\"Success! You are all set to proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbeee0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mFROM\u001b[39;49;00m \u001b[33mpython:3.8-slim-buster\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mRUN\u001b[39;49;00m pip3 install \u001b[31mpandas\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.1.4 \u001b[31mnumpy\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.19.4 scikit-learn==\u001b[34m0\u001b[39;49;00m.23.2 \u001b[31mscipy\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.5.4 \u001b[31mboto3\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.17.12\n",
      "\n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m /home\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mCOPY\u001b[39;49;00m src/* /home/\n",
      "\n",
      "\u001b[34mENTRYPOINT\u001b[39;49;00m [\u001b[33m\"python3\"\u001b[39;49;00m, \u001b[33m\"drift_detector.py\"\u001b[39;49;00m]\n"
     ]
    }
   ],
   "source": [
    "!pygmentize Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f049896d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building docker image custom-model-monitor from Dockerfile\n",
      "$ docker build -t custom-model-monitor -f Dockerfile .\n",
      "Sending build context to Docker daemon  38.43MB\n",
      "Step 1/5 : FROM python:3.8-slim-buster\n",
      "3.8-slim-buster: Pulling from library/python\n",
      "f6e04ba65310: Pulling fs layer\n",
      "b87859229fd4: Pulling fs layer\n",
      "598a5d7238e9: Pulling fs layer\n",
      "be1d88d97f44: Pulling fs layer\n",
      "22a630315c5a: Pulling fs layer\n",
      "22a630315c5a: Waiting\n",
      "be1d88d97f44: Waiting\n",
      "b87859229fd4: Verifying Checksum\n",
      "b87859229fd4: Download complete\n",
      "598a5d7238e9: Verifying Checksum\n",
      "598a5d7238e9: Download complete\n",
      "f6e04ba65310: Verifying Checksum\n",
      "f6e04ba65310: Download complete\n",
      "be1d88d97f44: Verifying Checksum\n",
      "be1d88d97f44: Download complete\n",
      "22a630315c5a: Verifying Checksum\n",
      "22a630315c5a: Download complete\n",
      "f6e04ba65310: Pull complete\n",
      "b87859229fd4: Pull complete\n",
      "598a5d7238e9: Pull complete\n",
      "be1d88d97f44: Pull complete\n",
      "22a630315c5a: Pull complete\n",
      "Digest: sha256:03c12f7bbd977120133b73e4b3ef5c5707ca09be338156dc02306d41633db4c0\n",
      "Status: Downloaded newer image for python:3.8-slim-buster\n",
      " ---> 5f3ce1d922f0\n",
      "Step 2/5 : RUN pip3 install pandas==1.1.4 numpy==1.19.4 scikit-learn==0.23.2 scipy==1.5.4 boto3==1.17.12\n",
      " ---> Running in 2229256c8ca7\n",
      "Collecting pandas==1.1.4\n",
      "  Downloading pandas-1.1.4-cp38-cp38-manylinux1_x86_64.whl (9.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.3/9.3 MB 107.8 MB/s eta 0:00:00\n",
      "Collecting numpy==1.19.4\n",
      "  Downloading numpy-1.19.4-cp38-cp38-manylinux2010_x86_64.whl (14.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.5/14.5 MB 104.1 MB/s eta 0:00:00\n",
      "Collecting scikit-learn==0.23.2\n",
      "  Downloading scikit_learn-0.23.2-cp38-cp38-manylinux1_x86_64.whl (6.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.8/6.8 MB 43.7 MB/s eta 0:00:00\n",
      "Collecting scipy==1.5.4\n",
      "  Downloading scipy-1.5.4-cp38-cp38-manylinux1_x86_64.whl (25.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 25.8/25.8 MB 15.6 MB/s eta 0:00:00\n",
      "Collecting boto3==1.17.12\n",
      "  Downloading boto3-1.17.12-py2.py3-none-any.whl (130 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.3/130.3 KB 3.2 MB/s eta 0:00:00\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2022.4-py2.py3-none-any.whl (500 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 500.8/500.8 KB 6.3 MB/s eta 0:00:00\n",
      "Collecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 KB 4.0 MB/s eta 0:00:00\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 298.0/298.0 KB 51.7 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting botocore<1.21.0,>=1.20.12\n",
      "  Downloading botocore-1.20.112-py2.py3-none-any.whl (7.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.7/7.7 MB 44.6 MB/s eta 0:00:00\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 73.4/73.4 KB 19.1 MB/s eta 0:00:00\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 140.4/140.4 KB 33.7 MB/s eta 0:00:00\n",
      "Collecting six>=1.5\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, urllib3, threadpoolctl, six, numpy, joblib, jmespath, scipy, python-dateutil, scikit-learn, pandas, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.17.12 botocore-1.20.112 jmespath-0.10.0 joblib-1.2.0 numpy-1.19.4 pandas-1.1.4 python-dateutil-2.8.2 pytz-2022.4 s3transfer-0.3.7 scikit-learn-0.23.2 scipy-1.5.4 six-1.16.0 threadpoolctl-3.1.0 urllib3-1.26.12\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container 2229256c8ca7\n",
      " ---> 561b62b4864a\n",
      "Step 3/5 : WORKDIR /home\n",
      " ---> Running in f76752c21d0f\n",
      "Removing intermediate container f76752c21d0f\n",
      " ---> 09575073e71f\n",
      "Step 4/5 : COPY src/* /home/\n",
      " ---> 50198eec1da2\n",
      "Step 5/5 : ENTRYPOINT [\"python3\", \"drift_detector.py\"]\n",
      " ---> Running in 660d144885b2\n",
      "Removing intermediate container 660d144885b2\n",
      " ---> 5ba9a1a09529\n",
      "Successfully built 5ba9a1a09529\n",
      "Successfully tagged custom-model-monitor:latest\n",
      "Done building docker image custom-model-monitor\n",
      "ECR repository already exists: custom-model-monitor\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Logged into ECR\n",
      "$ docker tag custom-model-monitor 806174985048.dkr.ecr.ap-northeast-2.amazonaws.com/custom-model-monitor\n",
      "Pushing docker image to ECR repository 806174985048.dkr.ecr.ap-northeast-2.amazonaws.com/custom-model-monitor\n",
      "\n",
      "$ docker push 806174985048.dkr.ecr.ap-northeast-2.amazonaws.com/custom-model-monitor\n",
      "Using default tag: latest\n",
      "The push refers to repository [806174985048.dkr.ecr.ap-northeast-2.amazonaws.com/custom-model-monitor]\n",
      "9032f65f5b77: Preparing\n",
      "8dd81c126ca4: Preparing\n",
      "cfe05f7405a2: Preparing\n",
      "a1e58b9ffda7: Preparing\n",
      "4b3c39c2c8a9: Preparing\n",
      "da1083ea5389: Preparing\n",
      "f362f5e58c99: Preparing\n",
      "da1083ea5389: Waiting\n",
      "f362f5e58c99: Waiting\n",
      "9032f65f5b77: Pushed\n",
      "a1e58b9ffda7: Pushed\n",
      "cfe05f7405a2: Pushed\n",
      "da1083ea5389: Pushed\n",
      "4b3c39c2c8a9: Pushed\n",
      "f362f5e58c99: Pushed\n",
      "8dd81c126ca4: Pushed\n",
      "latest: digest: sha256:a0ab28c69c28b9699727ba585c8b95381e9f720ebdba92a91cd175580174e9bc size: 1791\n",
      "Done pushing 806174985048.dkr.ecr.ap-northeast-2.amazonaws.com/custom-model-monitor\n"
     ]
    }
   ],
   "source": [
    "from docker_utils import build_and_push_docker_image\n",
    "\n",
    "repository_short_name = 'custom-model-monitor'\n",
    "\n",
    "image_name = build_and_push_docker_image(repository_short_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d7ff652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m#  Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m#  Licensed under the Apache License, Version 2.0 (the \"License\").\u001b[39;49;00m\n",
      "\u001b[37m#  You may not use this file except in compliance with the License.\u001b[39;49;00m\n",
      "\u001b[37m#  A copy of the License is located at\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m#      http://www.apache.org/licenses/LICENSE-2.0\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m#  or in the \"license\" file accompanying this file. This file is distributed\u001b[39;49;00m\n",
      "\u001b[37m#  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\u001b[39;49;00m\n",
      "\u001b[37m#  express or implied. See the License for the specific language governing\u001b[39;49;00m\n",
      "\u001b[37m#  permissions and limitations under the License.\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpathlib\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mio\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m StringIO\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_xgboost_container\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mencoder\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mxgb_encoders\u001b[39;49;00m\n",
      "\n",
      "\n",
      "script_path = pathlib.Path(\u001b[31m__file__\u001b[39;49;00m).parent.absolute()\n",
      "\u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mscript_path\u001b[33m}\u001b[39;49;00m\u001b[33m/preprocess.pkl\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "    preprocess = pickle.load(f) \n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(request_body, content_type):\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    The SageMaker XGBoost model server receives the request data body and the content type,\u001b[39;49;00m\n",
      "\u001b[33m    and invokes the `input_fn`.\u001b[39;49;00m\n",
      "\u001b[33m    Return a DMatrix (an object that can be passed to predict_fn).\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m content_type == \u001b[33m\"\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:        \n",
      "        df = pd.read_csv(StringIO(request_body), header=\u001b[34mNone\u001b[39;49;00m)\n",
      "        X = preprocess.transform(df)\n",
      "        \n",
      "        X_csv = StringIO()\n",
      "        pd.DataFrame(X).to_csv(X_csv, header=\u001b[34mFalse\u001b[39;49;00m, index=\u001b[34mFalse\u001b[39;49;00m)\n",
      "        req_transformed = X_csv.getvalue().replace(\u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "                \n",
      "        \u001b[34mreturn\u001b[39;49;00m xgb_encoders.csv_to_dmatrix(req_transformed)\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mContent type \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m is not supported.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(content_type)\n",
      "        )\n",
      "        \n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    Deserialize and return fitted model.\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \n",
      "    model_file = \u001b[33m\"\u001b[39;49;00m\u001b[33mxgboost-model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    booster = pickle.load(\u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, model_file), \u001b[33m\"\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "        \n",
      "    \u001b[34mreturn\u001b[39;49;00m booster    \n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd6335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "model_url = f's3://{bucket}/{s3_model_key}'\n",
    "\n",
    "xgb_inference_model = XGBoostModel(\n",
    "    model_data=model_url,\n",
    "    role=role,\n",
    "    entry_point='inference.py',\n",
    "    source_dir='src',\n",
    "    framework_version='1.2-1',\n",
    ")\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "                        enable_capture=True,\n",
    "                        sampling_percentage=100,\n",
    "                        destination_s3_uri=s3_capture_upload_path)\n",
    "\n",
    "predictor = xgb_inference_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    serializer=CSVSerializer(),\n",
    "    data_capture_config=data_capture_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585de618",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_path = f's3://{bucket}/{s3_train_key}'\n",
    "s3_test_path = f's3://{bucket}/{s3_test_key}'\n",
    "s3_result_path = f's3://{bucket}/{prefix}/result/{predictor.endpoint_name}'\n",
    "\n",
    "sm_client.create_monitoring_schedule(\n",
    "    MonitoringScheduleName=predictor.endpoint_name,\n",
    "    MonitoringScheduleConfig={\n",
    "        'ScheduleConfig': {\n",
    "            'ScheduleExpression': 'cron(0 * ? * * *)'\n",
    "        },\n",
    "        'MonitoringJobDefinition': {\n",
    "            'MonitoringInputs': [\n",
    "                {\n",
    "                    'EndpointInput': {\n",
    "                        'EndpointName': predictor.endpoint_name,\n",
    "                        'LocalPath': '/opt/ml/processing/endpointdata'\n",
    "                    }\n",
    "                },\n",
    "            ],\n",
    "            'MonitoringOutputConfig': {\n",
    "                'MonitoringOutputs': [\n",
    "                    {\n",
    "                        'S3Output': {\n",
    "                            'S3Uri': s3_result_path,\n",
    "                            'LocalPath': '/opt/ml/processing/resultdata',\n",
    "                            'S3UploadMode': 'EndOfJob'\n",
    "                        }\n",
    "                    },\n",
    "                ]\n",
    "            },\n",
    "            'MonitoringResources': {\n",
    "                'ClusterConfig': {\n",
    "                    'InstanceCount': 1,\n",
    "                    'InstanceType': 'ml.c5.xlarge',\n",
    "                    'VolumeSizeInGB': 10\n",
    "                }\n",
    "            },\n",
    "            'MonitoringAppSpecification': {\n",
    "                'ImageUri': image_name,\n",
    "                'ContainerArguments': [\n",
    "                    '--train_s3_uri',\n",
    "                    s3_train_path,\n",
    "                    '--test_s3_uri',\n",
    "                    s3_test_path,\n",
    "                    '--target_label',\n",
    "                    'income'\n",
    "                ]\n",
    "            },\n",
    "            'StoppingCondition': {\n",
    "                'MaxRuntimeInSeconds': 600\n",
    "            },\n",
    "            'Environment': {\n",
    "                'string': 'string'\n",
    "            },\n",
    "            'RoleArn': role\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d23021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from time import time, sleep\n",
    "\n",
    "def invoke_endpoint(ep_name, file_name, runtime_client):\n",
    "    pre_time = time()\n",
    "    with open(file_name) as f:\n",
    "        count = len(f.read().split('\\n')) - 2 # Remove EOF and header\n",
    "    \n",
    "    # Calculate time needed to sleep between inference calls if we need to have a constant rate of calls for 10 hours\n",
    "    ten_hours_in_sec = 10*60*60\n",
    "    sleep_time = ten_hours_in_sec/count\n",
    "    \n",
    "    with open(file_name, 'r') as f:\n",
    "        next(f) # Skip header\n",
    "        \n",
    "        for ind, row in enumerate(f):   \n",
    "            start_time = time()\n",
    "            payload = row.rstrip('\\n')\n",
    "            response = runtime_client(data=payload)\n",
    "            \n",
    "            # Print every 15 minutes (900 seconds)\n",
    "            if (ind+1) % int(count/ten_hours_in_sec*900) == 0:\n",
    "                print(f'Finished sending {ind+1} records.')\n",
    "            \n",
    "            # Sleep to ensure constant rate. Time spent for inference is subtracted\n",
    "            sleep(max(sleep_time - (time() - start_time), 0))\n",
    "                \n",
    "    print(\"Done!\")\n",
    "    \n",
    "print(f\"Sending test traffic to the endpoint {predictor.endpoint_name}. \\nPlease wait...\")\n",
    "\n",
    "thread = Thread(target = invoke_endpoint, args=(predictor.endpoint, 'data/infer.csv', predictor.predict))\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f896b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 1\n",
    "\n",
    "import sys\n",
    "from threading import Timer\n",
    "\n",
    "sys.path.append('src')\n",
    "\n",
    "%aimport drift_visualizer\n",
    "%aimport utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy():\n",
    "    df = utils.construct_df_from_result(s3_result_path)\n",
    "    if df is not None:    \n",
    "        drift_visualizer.plot_accuracy(df)\n",
    "    Timer(3600, plot_accuracy)\n",
    "    \n",
    "plot_accuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8758f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_drift_score():\n",
    "    df = utils.construct_df_from_result(s3_result_path) \n",
    "    if df is not None:    \n",
    "        drift_visualizer.plot_drift_score(df)\n",
    "    Timer(3600, plot_drift_score)\n",
    "    \n",
    "plot_drift_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd8be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_p_values():\n",
    "    df = utils.construct_df_from_result(s3_result_path)   \n",
    "    if df is not None:            \n",
    "        drift_visualizer.plot_p_values(df)\n",
    "    Timer(3600, plot_p_values)\n",
    "    \n",
    "plot_p_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b164cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
